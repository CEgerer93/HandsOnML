{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62040245",
   "metadata": {},
   "source": [
    "***EXERCISE 1 - BUILD A CLASSIFIER FOR THE MNIST DATASET THAT ACHIEVES OVER 97% ACCURACY ON THE TEST SET***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5b8ab3-a396-43d0-b8b7-491bc928abb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 785)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = arff.loadarff('%s/Downloads/mnist_784.arff'%os.environ['HOME'])\n",
    "df = pd.DataFrame(data[0])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9edb06-594b-4335-9573-8c0e2c07e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "X, y_raw = df.copy(), df['class']\n",
    "X.drop('class',axis=1,inplace=True)\n",
    "\n",
    "# Convert dtype of y to strings\n",
    "y = y_raw.to_numpy('str')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec372cd9-9445-47d2-ab6c-8ef2f370ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets - NOTE: MNIST is already shuffled\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada5721-2fec-413c-adaf-9d00ab89ab12",
   "metadata": {},
   "source": [
    "Build a classifier that achieves > 97% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dd3edf-9ba5-4b10-8e58-c865276c33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid search on weights and n_neighbors hyperparameters\n",
    "param_grid = [\n",
    "    {'n_neighbors': [3,4,5,6], 'weights': ['uniform', 'distance'] }\n",
    "]\n",
    "\n",
    "# Init the classifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# Create the grid_search\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2e8ab1-28e8-4d58-9023-ce322fa4f068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the grid search - this takes awhile\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    705\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    707\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 708\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:444\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_passthrough_scorer\u001b[39m(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    443\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:668\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:824\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    817\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    820\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    821\u001b[0m     )\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 824\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    836\u001b[0m ):\n\u001b[1;32m    837\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    838\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    839\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:277\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    290\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    291\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    298\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:95\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/threadpoolctl.py:171\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the grid search - this takes awhile\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58acccb1-b8b5-4626-bc63-505c1dab401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If opening notebook from a previous session wherein grid_search has been run,\n",
    "# simply set grid_search's best_params_. Otherwise, fetch best_params_ from instance above\n",
    "\n",
    "grid_search.best_params_ = {'n_neighbors': 4, 'weights': 'distance'}\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b90a24-7a44-4257-be4d-a35a0fe9a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2115ec51-ceb3-4c1d-860c-adb063102620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9849196244702746 {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.9854525187276485 {'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.9841239759298622 {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.9857061766402129 {'n_neighbors': 4, 'weights': 'distance'}\n",
      "0.9845218805762184 {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.9850972879196586 {'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.9839207285142436 {'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.9855117114135851 {'n_neighbors': 6, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(np.sqrt(mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a5c524-ad84-4021-acb0-21ec5b86674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters are:\n",
    "#.  n_neighbors = 4\n",
    "#.  weights = 'distance'\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Now create a classifier with these parameters and fit to training data\n",
    "knn_clf_best = KNeighborsClassifier(n_neighbors=4,weights='distance')\n",
    "\n",
    "# Instead of fitting the test set, let's fit the training set via cross-validation\n",
    "# This will give a sense of performance of classifier before applying it to test set\n",
    "y_train_knn_clf_best = cross_val_predict(knn_clf_best, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e6fc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716166666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess accuracy of knn_clf_best\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy exceeds 97%! \n",
    "accuracy_score(y_train, y_train_knn_clf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bacd3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fit the knn_clf_best classifier\n",
    "knn_clf_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7460cd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of knn_clf_best classifier on test set = 97.14 %\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "pred = knn_clf_best.predict(X_test)\n",
    "\n",
    "# Report accuracy without snooping the test set\n",
    "print(\"Accuracy of knn_clf_best classifier on test set = %.2f %%\"%\n",
    "     (accuracy_score(y_test,pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a01de9",
   "metadata": {},
   "source": [
    "***EXERCISE 2 - DATA AUGMENTATION: EXPAND MNIST DATASET BY SHIFTING IMAGES ONE PIXEL LEFT/RIGHT/UP/DOWN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7551f782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21057/335493721.py:2: DeprecationWarning: Please use `shift` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import shift\n"
     ]
    }
   ],
   "source": [
    "# Define a function to shift an image by one pixel up, down, left, or right\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def shiftDigit(digit,by=''):\n",
    "    # Reshape the digit represented as a pandas series\n",
    "    d = digit.values.reshape(28,28)\n",
    "    \n",
    "    # How to shift the digit\n",
    "    if by == 'r':\n",
    "        augDigit = shift(d, [0, 1], cval=0)\n",
    "    elif by == 'l':\n",
    "        augDigit = shift(d, [0, -1], cval=0)\n",
    "    elif by == 'u':\n",
    "        augDigit = shift(d, [-1, 0], cval=0)\n",
    "    elif by == 'd':\n",
    "        augDigit = shift(d, [1, 0], cval=0)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid shift by control : %s\"%by)\n",
    "    \n",
    "    return pd.Series(augDigit.reshape(28*28))\n",
    "\n",
    "def showDigit(digit):\n",
    "    plt.imshow(digit.values.reshape(28,28),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "80a63c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the labels; since shifted images correspond to same labels, simply duplicate the labels\n",
    "import numpy as np\n",
    "y_train_expand = np.concatenate((y_train,y_train,y_train,y_train,y_train))\n",
    "y_train_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "601dadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift each digit in training set left/right/up/down\n",
    "X_train_l = X_train.copy()\n",
    "X_train_r = X_train.copy()\n",
    "X_train_u = X_train.copy()\n",
    "X_train_d = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d43e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply shifting function\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_l.iloc[i] = shiftDigit(X_train.iloc[i],by='l')\n",
    "    X_train_r.iloc[i] = shiftDigit(X_train.iloc[i],by='r')\n",
    "    X_train_u.iloc[i] = shiftDigit(X_train.iloc[i],by='u')\n",
    "    X_train_d.iloc[i] = shiftDigit(X_train.iloc[i],by='d')\n",
    "\n",
    "X_train_expand = pd.concat([X_train, X_train_l, X_train_r, X_train_u, X_train_d],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a2111b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the knn_clf_best classifier from exercise 1 to the expanded set\n",
    "X_train_expand.shape, y_train_expand.shape\n",
    "\n",
    "knn_clf_best.fit(X_train_expand, y_train_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0cb1ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of knn_clf_best classifier on test set = 97.63%\n"
     ]
    }
   ],
   "source": [
    "# Apply trained knn_clf_best on original test set\n",
    "pred_expand = knn_clf_best.predict(X_test)\n",
    "print(\"Accuracy of knn_clf_best classifier on test set = %.2f%%\"%(accuracy_score(y_test,pred_expand)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6af0456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Augmenting the data only led to ~0.5% increase in accuracy when applied to the test set\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b98ae",
   "metadata": {},
   "source": [
    "***EXERCISE 3 - THE TITANIC DATASET***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69fde529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age has 177 NaNs, representing 19.87% of total\n",
      "Cabin has 687 NaNs, representing 77.10% of total\n",
      "Embarked has 2 NaNs, representing 0.22% of total\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "titanic_test = pd.read_csv('%s/kaggle/datasets/titanic/test.csv'%os.environ['HOME'])\n",
    "titanic_train_raw = pd.read_csv('%s/kaggle/datasets/titanic/train.csv'%os.environ['HOME'])\n",
    "\n",
    "# Report columns with NaNs\n",
    "def colNan(data):\n",
    "    for c in data.columns:\n",
    "        if data[c].isnull().values.any():\n",
    "            cntNull=data[c].isnull().sum()\n",
    "            print(\"%s has %i NaNs, representing %.2f%% of total\"%\n",
    "                  (c,cntNull,(100*cntNull/len(data[c]))))\n",
    "\n",
    "colNan(titanic_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02dc333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a substantial portion of 'Cabin' attributes being NaN, consider dropping the column all together.\n",
    "# 'Age' and 'Embarked' features are NaN < 20% and < 1%, respectively. So consider\n",
    "# using an imputer to replace missing 'Age' values with mean or median of said column,\n",
    "# and drop DataFrame indices where Embarked is NaN.\n",
    "\n",
    "# Drop 'Cabin' & 'Name', as the latter is conceivably irrelevant to survival\n",
    "titanic_train_raw = titanic_train_raw.drop(['Cabin','Name'],axis=1)\n",
    "titanic_train_raw.dropna(subset=['Embarked'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6103c4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 8) (889,) (418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
       "PassengerId                                                                  \n",
       "1                 3    male  22.0      1      0         A/5 21171   7.2500   \n",
       "2                 1  female  38.0      1      0          PC 17599  71.2833   \n",
       "3                 3  female  26.0      0      0  STON/O2. 3101282   7.9250   \n",
       "4                 1  female  35.0      1      0            113803  53.1000   \n",
       "5                 3    male  35.0      0      0            373450   8.0500   \n",
       "\n",
       "            Embarked  \n",
       "PassengerId           \n",
       "1                  S  \n",
       "2                  C  \n",
       "3                  S  \n",
       "4                  S  \n",
       "5                  S  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the 'Survived' column from titanic_train_raw to use as labels\n",
    "titanic_train_labels = titanic_train_raw.Survived\n",
    "titanic_train = titanic_train_raw.drop(['Survived'], axis=1)\n",
    "\n",
    "# Set the PassengerId as index\n",
    "titanic_train.set_index('PassengerId',inplace=True)\n",
    "\n",
    "# Shapes of train/test data\n",
    "print(titanic_train.shape, titanic_train_labels.shape, titanic_test.shape)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "275ba388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform missing values in 'Age' & 'Fare' features using mean imputer\n",
    "# M = mean_imputer.transform(titanic_train_numeric)\n",
    "\n",
    "# # Convert result to a DataFrame and map columns to titanic_train\n",
    "# titanic_train_numeric_filled = pd.DataFrame(M, columns=titanic_train_numeric.columns,\n",
    "#                                            index=titanic_train_numeric.index)\n",
    "\n",
    "# titanic_train.Age = titanic_train_numeric_filled.Age\n",
    "# titanic_train.Fare = titanic_train_numeric_filled.Fare\n",
    "\n",
    "# titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ab3ba7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count      889\n",
       " unique       2\n",
       " top       male\n",
       " freq       577\n",
       " Name: Sex, dtype: object,\n",
       " count        889\n",
       " unique       680\n",
       " top       347082\n",
       " freq           7\n",
       " Name: Ticket, dtype: object,\n",
       " count     889\n",
       " unique      3\n",
       " top         S\n",
       " freq      644\n",
       " Name: Embarked, dtype: object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate categorical features & describe\n",
    "titanic_train_cat = titanic_train.drop(['Pclass','Age','SibSp','Parch','Fare'], axis=1)\n",
    "titanic_train_cat.Sex.describe(), titanic_train_cat.Ticket.describe(), titanic_train_cat.Embarked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b47c9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make use of pipelines\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define numerical and categorical attributes\n",
    "num_attribs = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_attribs = ['Sex', 'Embarked']\n",
    "\n",
    "# Define pipeline for numerical attributes\n",
    "numeric_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "# # Define pipeline for categorical attributes\n",
    "# cat_pipe = Pipeline([\n",
    "#     ('ohe', OneHotEncoder(), cat_attribs)\n",
    "# ])\n",
    "\n",
    "# Define a full pipeline for the columns\n",
    "# Consider OneHotEncoder for Sex & Embarked attributes (each takes of discrete values w/ no inherent order)\n",
    "full_pipe = ColumnTransformer([\n",
    "    ('num', numeric_pipe, num_attribs),\n",
    "    ('cat', OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "titanic_train_prepared = full_pipe.fit_transform(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e9aa6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    , 22.    ,  1.    ,  0.    ,  7.25  ,  0.    ,  1.    ,\n",
       "         0.    ,  0.    ,  1.    ],\n",
       "       [ 1.    , 38.    ,  1.    ,  0.    , 71.2833,  1.    ,  0.    ,\n",
       "         1.    ,  0.    ,  0.    ],\n",
       "       [ 3.    , 26.    ,  0.    ,  0.    ,  7.925 ,  1.    ,  0.    ,\n",
       "         0.    ,  0.    ,  1.    ],\n",
       "       [ 1.    , 35.    ,  1.    ,  0.    , 53.1   ,  1.    ,  0.    ,\n",
       "         0.    ,  0.    ,  1.    ],\n",
       "       [ 3.    , 35.    ,  0.    ,  0.    ,  8.05  ,  0.    ,  1.    ,\n",
       "         0.    ,  0.    ,  1.    ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train_prepared[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7252f970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=1)\n",
    "sgd_clf.fit(titanic_train_prepared, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7f650cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained SGDClassifier fit to prepared training data achieves 78.74% accuracy\n"
     ]
    }
   ],
   "source": [
    "# Use trained model to predict the labels of training set, and look at accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = sgd_clf.predict(titanic_train_prepared)\n",
    "print(\"Trained SGDClassifier fit to prepared training data achieves %.2f%% accuracy\"%\n",
    "     (100*accuracy_score(titanic_train_labels,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2447b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider cross validation to assess performance of sgd_clf\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "fold_predictions = cross_val_predict(sgd_clf, titanic_train_prepared, titanic_train_labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9f741ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(fold_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7da4e692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2fef818280>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_mat = confusion_matrix(titanic_train_labels, fold_predictions)\n",
    "plt.matshow(conf_mat, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "841b1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to generate results to submit\n",
    "def results(ids,predictions):\n",
    "    sub = pd.DataFrame({\n",
    "                        'PassengerId': ids,\n",
    "                        'Survived': predictions\n",
    "                        }\n",
    "    )\n",
    "    \n",
    "    sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "daaffd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same data preparation steps to the test set\n",
    "titanic_test = titanic_test.drop(['Cabin','Name'],axis=1)\n",
    "titanic_test.dropna(subset=['Embarked'],inplace=True)\n",
    "titanic_test.set_index('PassengerId', inplace=True)\n",
    "\n",
    "# Save index\n",
    "indices = titanic_test.index\n",
    "\n",
    "titanic_test_prepared = full_pipe.fit_transform(titanic_test)\n",
    "\n",
    "results(indices, sgd_clf.predict(titanic_test_prepared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075fd657",
   "metadata": {},
   "source": [
    "***EXERCISE 4 - BUILD A SPAM CLASSIFIER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789f0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = 'https://spamassassin.apache.org/old/publiccorpus/'\n",
    "HAM = ROOT + '20030228_easy_ham.tar.bz2'\n",
    "SPAM = ROOT + '20030228_spam.tar.bz2'\n",
    "PATH = os.path.join('apache-datasets','spam')\n",
    "\n",
    "def get_spam_n_ham(ham_url=HAM, spam_url=SPAM, path_to_data=PATH):\n",
    "    if not os.path.isdir(path_to_data):\n",
    "        os.makedirs(path_to_data)\n",
    "    for file, url in [('ham.tar.bz2', ham_url), ('spam.tar.bz2', spam_url)]:\n",
    "        path = os.path.join(path_to_data,file)\n",
    "        if not os.path.isfile(path):\n",
    "            # Download from url and place at path\n",
    "            print(\"Extracting from : %s\"%url)\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2 = tarfile.open(path)\n",
    "        tar_bz2.extractall(path=path_to_data)\n",
    "        tar_bz2.close()\n",
    "        \n",
    "        \n",
    "get_spam_n_ham()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143f4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spam/ham examples are named according to <message #>.<MD5 sum>\n",
    "\n",
    "# Set paths to spam and easy_ham\n",
    "HAMPATH = os.path.join(os.getcwd(),'apache-datasets','spam','easy_ham')\n",
    "SPAMPATH = os.path.join(os.getcwd(),'apache-datasets','spam','spam')\n",
    "\n",
    "# Access names of each easy_ham and spam message\n",
    "HAM = [os.path.join(HAMPATH,f) for f in os.listdir(HAMPATH) if os.path.isfile(os.path.join(HAMPATH,f)) and f != 'cmds']\n",
    "SPAM = [os.path.join(SPAMPATH,f) for f in os.listdir(SPAMPATH) if os.path.isfile(os.path.join(SPAMPATH,f)) and f != 'cmds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36d3d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(HAM), len(SPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1cd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the email module, define a function to parse the email messages\n",
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "def read_email(email):\n",
    "    # Read the email file\n",
    "    with open(email, 'rb') as file:\n",
    "        # Parse the email content\n",
    "        return BytesParser(policy=policy.default).parse(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3574b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the spam and ham emails\n",
    "emails_ham = [read_email(e) for e in HAM]\n",
    "emails_spam = [read_email(e) for e in SPAM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05779935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On a RH 8 box, I'm trying to install your package\\nxine-0.9.13-fr5.i386.rpm, I keep running into dependency problems.  I've\\ntried to install the dev and lib rpm's as well and they error out with\\ndependency problems on each other (they each want something from the\\nother's package).\\n\\nI've tried the --without options, but still end up with (similar for the\\nregular package),\\n\\n\\tglut is needed by xine-libs-0.9.13-fr5\\n        aalib is needed by xine-libs-0.9.13-fr5\\n        lirc is needed by xine-libs-0.9.13-fr5\\n        libaa.so.1 is needed by xine-libs-0.9.13-fr5\\n        libglut.so.3 is needed by xine-libs-0.9.13-fr5\\n\\nWhat am I missing here?\\n\\nThanks for your efforts.\\nQuaffAPint\\n\\n\\n\\n\\n\\n\\n_______________________________________________\\nRPM-List mailing list <RPM-List@freshrpms.net>\\nhttp://lists.freshrpms.net/mailman/listinfo/rpm-list\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at a ham email (removing leading/trailing whitespace)\n",
    "emails_ham[0].get_content().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280c7283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Earn Extra Income From Home. Here is tremendous\\nopportunity to earn big money. We are a multimillion\\ncompany that is growing at a rate of 1000% per year.\\nWe are looking for motivated individuals who are\\nlooking to earn a substantial income from home.\\n\\nThis is what you been waiting for a chance to be\\nfinancially secure.  Earn Extra Income From Home. Here\\nis a tremendous opportunity to earn\\n No experience is required. We will provide the\\ntraining you may need. \\n\\nWe are looking for energetic and self- motivated\\npeople that want to change their life. If that is you\\nclick the link below and complete our online\\ninformation request form, and one of our employment\\nspecialist will contact you.\\n\\nhttp://ter.netblah.com:27000\\n\\nGot nothing to lose and a lot to gain, with a career\\nthat will provide you cast opportunities and\\nsubstantial income. Please fill our online information\\nrequest form here:\\n\\nhttp://ter.netblah.com:27000\\n\\nTo remove from our list simply click on the link below\\nnow:\\n\\nhttp://ter.netblah.com:27000/remove.html\\n \\n\\n \\n\\n9986dxkU6-303JWSp0699MAYXl24'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at a spam email (removing leading/trailing whitespace)\n",
    "emails_spam[1].get_content().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c045049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multipart/signed\n",
      "[<email.message.EmailMessage object at 0x7f42f30a4cd0>, <email.message.EmailMessage object at 0x7f42f30a4c10>]\n",
      "text/plain\n",
      "application/pgp-signature\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate utility of get_payload() and get_content_type()\n",
    "print(emails_ham[1].get_content_type()) # email is a multipart/signed\n",
    "print(emails_ham[1].get_payload()) # list of each EmailMessage object comprising multipart/signed email\n",
    "print(emails_ham[1].get_payload(0).get_content_type()) # content_type of first EmailMessage object\n",
    "print(emails_ham[1].get_payload(1).get_content_type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cb72e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/plain                                                                                                                   2408\n",
      "multipart(text/plain, application/pgp-signature)                                                                               66\n",
      "multipart(text/plain, text/html)                                                                                                8\n",
      "multipart(text/plain, text/plain)                                                                                               4\n",
      "multipart(text/plain)                                                                                                           3\n",
      "multipart(text/plain, application/octet-stream)                                                                                 2\n",
      "multipart(text/plain, application/x-pkcs7-signature)                                                                            1\n",
      "multipart(text/plain, video/mng)                                                                                                1\n",
      "multipart(text/plain, application/x-java-applet)                                                                                1\n",
      "multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)                                                   1\n",
      "multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)                                             1\n",
      "multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))       1\n",
      "multipart(text/plain, application/ms-tnef, text/plain)                                                                          1\n",
      "multipart(text/plain, text/enriched)                                                                                            1\n",
      "multipart(text/plain, multipart(text/plain))                                                                                    1\n",
      "Name: count, dtype: int64\n",
      "text/plain                                                               218\n",
      "text/html                                                                183\n",
      "multipart(text/plain, text/html)                                          45\n",
      "multipart(text/html)                                                      20\n",
      "multipart(text/plain)                                                     19\n",
      "multipart(multipart(text/html))                                            5\n",
      "multipart(text/plain, image/jpeg)                                          3\n",
      "multipart(text/html, application/octet-stream)                             2\n",
      "multipart(text/html, text/plain)                                           1\n",
      "multipart(multipart(text/html), application/octet-stream, image/jpeg)      1\n",
      "multipart(multipart(text/plain, text/html), image/gif)                     1\n",
      "multipart/alternative                                                      1\n",
      "multipart(text/plain, application/octet-stream)                            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Some emails are more than just text...\n",
    "# Namely, emails_spam[1].get_content().strip() returns: \"KeyError: 'multipart/mixed'\"\n",
    "\n",
    "# Use get_payload() to return:\n",
    "#   - list of email.message.EmailMessage objects when is_multipart()=True\n",
    "#   - or a string when is_multipart()=False\n",
    "\n",
    "# Define a function to determine an email's structure\n",
    "def email_structure(email):\n",
    "    # Immediately return if email is a simple string\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    # Otherwise, use get_payload() to determine message parts\n",
    "    components = email.get_payload()\n",
    "    \n",
    "    # Recursively call email_structure() and determine content_type of each piece of multipart\n",
    "    if isinstance(components, list):\n",
    "        return 'multipart({})'.format(', '.join([email_structure(c) for c in components]))\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "        \n",
    "    \n",
    "# Collect the unique email structures for the ham and spam emails\n",
    "uniq_structures_ham = [email_structure(email) for email in emails_ham]\n",
    "uniq_structures_spam = [email_structure(email) for email in emails_spam]\n",
    "\n",
    "# Unique ham structures\n",
    "print(pd.Series(uniq_structures_ham).value_counts())\n",
    "# Unique spam structures\n",
    "print(pd.Series(uniq_structures_spam).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0ff2b",
   "metadata": {},
   "source": [
    "# Observations\n",
    "- While both spam and ham emails are mostly represented as text/plain, each set contains multipart emails too\n",
    "- The multipart emails include\n",
    "    - videos\n",
    "    - images\n",
    "    - html\n",
    "    - etc.\n",
    "- Of note, some spam email messages are simple text/html, while no ham email is just html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4b6a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"> From:  Valdis.Kletnieks@vt.edu\\\\n> Date:  Mon, 26 Aug 2002 14:22:46 -0400\\\\n>\\\\n> I\\'m perfectly willing to can-opener that code and see where the CPU is\\\\n> going, but only if nobody is slapping their forehead and mumbling about\\\\n> a brown-paper-bag bug... ;)\\\\n\\\\nAs I mentioned in my email to Anders, it\\'s certainly in my code and I don\\'t \\\\nhave time to work on it right now, so I would not be offended if you worked on \\\\nit.\\\\n\\\\nI just this moment found out that my partner has promised a few things would be \\\\ndone before my vacation that will require my efforts, so it\\'s even more true \\\\nthat it was when I sent the mail to Anders.\\\\n\\\\nChris\\\\n\\\\n-- \\\\nChris Garrigues                 http://www.DeepEddy.Com/~cwg/\\\\nvirCIO                          http://www.virCIO.Com\\\\n716 Congress, Suite 200\\\\nAustin, TX  78701\\\\t\\\\t+1 512 374 0500\\\\n\\\\n  World War III:  The Wrong-Doers Vs. the Evil-Doers.\\\\n\\\\n\\\\n\\\\n\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emails_ham[0].keys()   : return list of all the message's header field names\n",
    "# emails_ham[0].values() : return list of all the message's field values\n",
    "# emails_ham[0].items()  : 2-tuples of keys/values of message's field headers and values\n",
    "\n",
    "class VerboseEmail:     \n",
    "    def set_email(self, email):\n",
    "        self.email=email\n",
    "        self.unixfrom=self.email.get_unixfrom()\n",
    "        self.contentType=self.email.get_content_type()\n",
    "        self.boundary=self.email.get_boundary()\n",
    "        self.items=self.email.items()\n",
    "        self._prefSuff_=' ---- '\n",
    "        return self\n",
    "    \n",
    "    def _unixfrom_(self):\n",
    "        return \"%sUNIXFROM%s\\n%s\\n\"%(self._prefSuff_, self._prefSuff_,\n",
    "                                    self.unixfrom)\n",
    "    \n",
    "    def _content_(self):\n",
    "        theContents=''\n",
    "        if self.email.is_multipart():\n",
    "            for part in self.email.walk():\n",
    "                ctype = part.get_content_type()\n",
    "                cdispo = str(part.get('Content-Disposition'))\n",
    "                \n",
    "                if ctype == 'text/plain' and 'attachment' not in cdispo:\n",
    "                    theContents = part.get_payload(decode=True)\n",
    "        else:\n",
    "            theContents += self.email.get_content()              \n",
    "        return str(theContents)\n",
    "    \n",
    "    def _boundary_(self):\n",
    "        return \"%sGET BOUNDARY%s\\n%s\\n\"%(self._prefSuff_, self._prefSuff_,\n",
    "                                        self.boundary)\n",
    "    \n",
    "    def _items_(self):\n",
    "        return \"%sITEMS%s\\n%s\\n\"%(self._prefSuff_, self._prefSuff_,\n",
    "                                 self.items)\n",
    "        \n",
    "    def info(self):\n",
    "        return print(self._unixfrom_()+\n",
    "                     '%sCONTENT [ %s ]%s\\n%s\\n'%(self._prefSuff_, self.contentType,\n",
    "                                                 self._prefSuff_,self._content_())+\n",
    "                    self._boundary_()+self._items_())\n",
    "    \n",
    "    def content(self):\n",
    "        return self._content_()\n",
    "\n",
    "vb=VerboseEmail()\n",
    "vb.set_email(emails_ham[1])\n",
    "# vb.info()\n",
    "vb.content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3843db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# BUILD UP A PIPELINE THAT CREATES FEATURES FROM THE EMAILS WITHIN EACH DATAFRAME\n",
    "################\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CleanEmail(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class to manage transforming a parsed email into a sparse vector for classification algorithms.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    lowercase : bool\n",
    "        Convert email to lowercase\n",
    "    \n",
    "    stripHeader : bool\n",
    "        Remove email header\n",
    "    \n",
    "    punctuation : bool\n",
    "        Remove punctuation\n",
    "    \n",
    "    urlStamp : bool\n",
    "        Replace any URLs with 'URL'\n",
    "    \n",
    "    numStamp : bool\n",
    "        Replace any numbers with 'NUMBER'\n",
    "    \"\"\"\n",
    "    def __init__(self, cleanHtml=False, lowercase=False, numStamp=False, punctuation=False,\n",
    "                 stripHeader=False, urlStamp=False):\n",
    "        self.cleanHtml=cleanHtml\n",
    "        self.lowercase=lowercase\n",
    "        self.numStamp=numStamp\n",
    "        self.punctuation=punctuation\n",
    "        self.stripHeader=stripHeader\n",
    "        self.urlStamp=urlStamp\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):        \n",
    "        if self.cleanHtml:\n",
    "            bleach = re.compile('<.*?>')\n",
    "            X.Email = X.Email.apply(lambda x: re.sub(bleach, '', x))\n",
    "        if self.urlStamp:\n",
    "            X.Email = X.Email.apply(lambda x: re.sub(r'(https?://\\S+)', 'URL', x))\n",
    "        if self.punctuation:\n",
    "            # Remove [tabs/new lines, multiple spaces, punctuation, underscores]\n",
    "            for regex,fill in { r'[\\r\\n\\t]+': ' ', r'\\s+': ' ', r'[^\\w\\s]': '', r'_': ''}.items():\n",
    "                X.Email = X.Email.apply(lambda x: re.sub(regex, fill, x))\n",
    "        if self.numStamp:\n",
    "            X.Email = X.Email.apply(lambda x: re.sub(r'\\b\\d+\\b', 'NUM', x))\n",
    "        if self.lowercase:\n",
    "            lowercase = X.Email.apply(lambda x: x.lower())\n",
    "            X.Email = lowercase\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        return X\n",
    "    \n",
    "class UniqueWords(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, on='', getUniq=True):\n",
    "        self.on=on\n",
    "        self.getUniq=getUniq\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Unique words split on single spaces (ignoring empty strings)\n",
    "        uniq_words = X[self.on].apply(lambda x: list(set(x.split(' '))-{''}))\n",
    "        X['unique_count'] = uniq_words.apply(lambda l: len(l))\n",
    "        X['unique_words'] = uniq_words.apply(lambda w: ' '.join(w))\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d93b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Instance of PorterStemmer class for stemming words\n",
    "ps = PorterStemmer()\n",
    "\n",
    "class Stemmer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stem=False):\n",
    "        self.stem=stem\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not self.stem:\n",
    "            pass\n",
    "        else:\n",
    "            X['Email_stemmed'] = X.Email.apply(lambda x: ' '.join([ps.stem(w) for w in x.split(' ')]))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6836945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class to convert a sentence into a feature vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class FeatureVector(BaseEstimator):\n",
    "    def __init__(self, binary=True):\n",
    "        # Instance of CountVectorizer setting denoting 1/0 for presence/absence of word\n",
    "        self.vectorizer = CountVectorizer(binary=binary)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Fit and transform the sentences to get the sparse matrix representation\n",
    "        sparse_matrix = self.vectorizer.fit_transform(X.unique_words)\n",
    "\n",
    "        # Get the feature names from the vectorizer\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Convert the sparse matrix to a dense array for better visibility\n",
    "        dense_array = sparse_matrix.toarray()\n",
    "        \n",
    "        X = pd.concat([X,pd.DataFrame(dense_array, columns=feature_names)],axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec21527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to clean an email, stem its contents, pick out unique words, then form feature vector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clean', CleanEmail(cleanHtml=True,lowercase=True, numStamp=True,punctuation=True,urlStamp=True)),\n",
    "    ('stem', Stemmer(stem=True)),\n",
    "    ('unique', UniqueWords(on='Email',getUniq=True)),\n",
    "    ('feature_vec', FeatureVector(binary=True)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3271fc88",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "unknown encoding: unknown-8bit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m293\u001b[39m \u001b[38;5;66;03m# this is the problem encoding...\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cleaned_ham \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmail\u001b[39m\u001b[38;5;124m'\u001b[39m: [vb\u001b[38;5;241m.\u001b[39mset_email(e)\u001b[38;5;241m.\u001b[39mcontent() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m emails_ham[:num]],\n\u001b[1;32m      3\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misSpam\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(emails_ham[:num]))})\n\u001b[0;32m----> 4\u001b[0m cleaned_spam \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmail\u001b[39m\u001b[38;5;124m'\u001b[39m: [vb\u001b[38;5;241m.\u001b[39mset_email(e)\u001b[38;5;241m.\u001b[39mcontent() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m emails_spam[:num]],\n\u001b[1;32m      5\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misSpam\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(emails_spam[:num]))})\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Transform cleaned_ham/spam by applying pipeline\u001b[39;00m\n\u001b[1;32m      8\u001b[0m filtered_ham \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(cleaned_ham)\n",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m293\u001b[39m \u001b[38;5;66;03m# this is the problem encoding...\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cleaned_ham \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmail\u001b[39m\u001b[38;5;124m'\u001b[39m: [vb\u001b[38;5;241m.\u001b[39mset_email(e)\u001b[38;5;241m.\u001b[39mcontent() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m emails_ham[:num]],\n\u001b[1;32m      3\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misSpam\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(emails_ham[:num]))})\n\u001b[0;32m----> 4\u001b[0m cleaned_spam \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmail\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[43mvb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_email\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m emails_spam[:num]],\n\u001b[1;32m      5\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misSpam\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(emails_spam[:num]))})\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Transform cleaned_ham/spam by applying pipeline\u001b[39;00m\n\u001b[1;32m      8\u001b[0m filtered_ham \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(cleaned_ham)\n",
      "Cell \u001b[0;32mIn[10], line 47\u001b[0m, in \u001b[0;36mVerboseEmail.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontent\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_content_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mVerboseEmail._content_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m             theContents \u001b[38;5;241m=\u001b[39m part\u001b[38;5;241m.\u001b[39mget_payload(decode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     theContents \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memail\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m              \n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(theContents)\n",
      "File \u001b[0;32m/usr/lib/python3.10/email/message.py:1096\u001b[0m, in \u001b[0;36mMIMEPart.get_content\u001b[0;34m(self, content_manager, *args, **kw)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m content_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1095\u001b[0m     content_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mcontent_manager\n\u001b[0;32m-> 1096\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontent_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/email/contentmanager.py:22\u001b[0m, in \u001b[0;36mContentManager.get_content\u001b[0;34m(self, msg, *args, **kw)\u001b[0m\n\u001b[1;32m     20\u001b[0m maintype \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mget_content_maintype()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maintype \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_handlers:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_handlers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmaintype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_handlers:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_handlers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m](msg, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/usr/lib/python3.10/email/contentmanager.py:67\u001b[0m, in \u001b[0;36mget_text_content\u001b[0;34m(msg, errors)\u001b[0m\n\u001b[1;32m     65\u001b[0m content \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mget_payload(decode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m charset \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASCII\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcharset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mLookupError\u001b[0m: unknown encoding: unknown-8bit"
     ]
    }
   ],
   "source": [
    "num=293 # this is the problem encoding...\n",
    "cleaned_ham = pd.DataFrame({'Email': [vb.set_email(e).content() for e in emails_ham[:num]],\n",
    "                            'isSpam': np.zeros(len(emails_ham[:num]))})\n",
    "cleaned_spam = pd.DataFrame({'Email': [vb.set_email(e).content() for e in emails_spam[:num]],\n",
    "                            'isSpam': np.ones(len(emails_spam[:num]))})\n",
    "\n",
    "# Transform cleaned_ham/spam by applying pipeline\n",
    "filtered_ham = pipeline.transform(cleaned_ham)\n",
    "filtered_spam = pipeline.transform(cleaned_spam)\n",
    "\n",
    "filtered_ham.head()\n",
    "filtered_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc8863da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>isSpam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/colin/ML/HandsOnML/Classification/apache...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/colin/ML/HandsOnML/Classification/apache...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/colin/ML/HandsOnML/Classification/apache...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/colin/ML/HandsOnML/Classification/apache...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/colin/ML/HandsOnML/Classification/apache...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Email  isSpam\n",
       "0  /home/colin/ML/HandsOnML/Classification/apache...       1\n",
       "1  /home/colin/ML/HandsOnML/Classification/apache...       1\n",
       "2  /home/colin/ML/HandsOnML/Classification/apache...       1\n",
       "3  /home/colin/ML/HandsOnML/Classification/apache...       1\n",
       "4  /home/colin/ML/HandsOnML/Classification/apache...       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add labels to HAM and SPAM indicating if they are spam\n",
    "d=dict([(h, False) for h in HAM])\n",
    "\n",
    "# Make dataframes of emails indicating whether they are spam or not\n",
    "df_ham = pd.DataFrame({'Email': HAM, 'isSpam': [0 for i in range(len(HAM))]})\n",
    "df_spam = pd.DataFrame({'Email': SPAM, 'isSpam': [1 for i in range(len(SPAM))]})\n",
    "df_ham.head()\n",
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab9c4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate df_ham and df_spam DataFrames\n",
    "df_emails= pd.concat([df_ham, df_spam])\n",
    "df_emails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "898c1c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2)\n",
      "(600, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isSpam\n",
       "0    1993\n",
       "1     407\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the emails dataframe into an 80/20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test_full = train_test_split(df_emails, test_size=0.2, random_state=10)\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(X_test_full.shape)\n",
    "\n",
    "# Confirm there are both easy_ham and spam instances in training set\n",
    "X_train_full.isSpam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbe32ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1) (2400,)\n",
      "(600, 1) (600,)\n"
     ]
    }
   ],
   "source": [
    "# Extract the labels from the X_{train,test}_fill dataframes\n",
    "# and use these to set training/test labels\n",
    "y_train = X_train_full.isSpam; y_test = X_test_full.isSpam\n",
    "X_train = X_train_full.drop(['isSpam'], axis=1)\n",
    "X_test = X_test_full.drop(['isSpam'], axis=1)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28fed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
